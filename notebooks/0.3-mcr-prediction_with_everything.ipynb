{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction with everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (22,23,24,32,33,34,44,46,59,64,116) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "csvs = pd.read_csv('../data/master.csv', index_col='SK_ID_CURR')\n",
    "sql = pd.read_csv('../data/processed/full_sql.csv', index_col='SK_ID_CURR')\n",
    "api = pd.read_csv('../data/api_data_clean.csv', index_col='sk_id_curr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_1 = pd.merge(sql, csvs, how='left', right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.merge(temp_1, api, how='left', right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = master[~master.TARGET.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = master.reindex(master.index.difference(train.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for col in master.columns:\n",
    "    if master[col].isnull().sum() > 50000:\n",
    "        a.append(col)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = []\n",
    "pattern = re.compile(\"FLAG|flag\")\n",
    "for col in master.columns:\n",
    "    if pattern.search(col):\n",
    "        flags.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_flags= ['FLAG_DOCUMENT_11_x', 'FLAG_DOCUMENT_14.1', 'FLAG_DOCUMENT_16_y',\n",
    "'FLAG_DOCUMENT_18_y', 'FLAG_DOCUMENT_3_y', 'FLAG_DOCUMENT_4_y', 'FLAG_DOCUMENT_6_y', \n",
    "            'FLAG_OWN_CAR_y', 'FLAG_OWN_REALTY_y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_DOCUMENT_7 = pd.to_numeric(master['FLAG_DOCUMENT_7_y'] + master['FLAG_DOCUMENT_7_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAG_DOCUMENT_8 = pd.to_numeric(master['FLAG_DOCUMENT_8_y'] + master['FLAG_DOCUMENT_8_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_flags(_df):\n",
    "    _df['FLAG_DOCUMENT_7'] = pd.to_numeric(_df['FLAG_DOCUMENT_7_y'] + _df['FLAG_DOCUMENT_7_x'])\n",
    "    _df['FLAG_DOCUMENT_8'] = pd.to_numeric(_df['FLAG_DOCUMENT_8_y'] + _df['FLAG_DOCUMENT_8_x'])\n",
    "\n",
    "    # These are duplicate \n",
    "    dupes_flags= ['FLAG_DOCUMENT_11_x', 'FLAG_DOCUMENT_14.1', 'FLAG_DOCUMENT_16_y',\n",
    "                'FLAG_DOCUMENT_18_y', 'FLAG_DOCUMENT_3_y', 'FLAG_DOCUMENT_4_y', 'FLAG_DOCUMENT_6_y', \n",
    "                'FLAG_OWN_CAR_y', 'FLAG_OWN_REALTY_y','FLAG_DOCUMENT_7_y','FLAG_DOCUMENT_7_x',\n",
    "                'FLAG_DOCUMENT_8_y','FLAG_DOCUMENT_8_x']    \n",
    "    \n",
    "    _df = _df.drop(columns=dupes_flags)\n",
    "    \n",
    "    # Columns with a lot of Nans\n",
    "    drop_cols=['FLAG_OWN_CAR_x','FLAG_DOCUMENT_16_x','FLAG_DOCUMENT_11_y'  ,'FLAG_DOCUMENT_2']\n",
    "    \n",
    "    ## Todo instead of dropping Nan maybe interpolate them?\n",
    "    _df = _df.drop(columns=drop_cols)\n",
    "    \n",
    "    # Fixing dtypes\n",
    "    _df['FLAG_OWN_REALTY_x'] = _df['FLAG_OWN_REALTY_x'].apply(lambda y: 1 if y =='Y' else 0)\n",
    "    _df['flag_document_9'] = _df['flag_document_9'].astype(int)\n",
    "    _df['flag_document_13'] = _df['flag_document_13'].astype(int)\n",
    "    \n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_flags = prepare_flags(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = []\n",
    "pattern = re.compile(\"FLAG|flag\")\n",
    "for col in master_flags.columns:\n",
    "    if pattern.search(col):\n",
    "        flags.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_flags = list(set(master_flags.columns) - set(flags))\n",
    "not_flags.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_x_y_merge(_df):\n",
    "    combine = ['AMT_CREDIT_x', 'AMT_INCOME_TOTAL_x', 'DEF_30_CNT_SOCIAL_CIRCLE_x', \n",
    "              'FLOORSMAX_AVG_x', 'LIVINGAPARTMENTS_AVG_x', 'OBS_60_CNT_SOCIAL_CIRCLE_x',\n",
    "              'YEARS_BEGINEXPLUATATION_AVG_x' ]\n",
    "    \n",
    "    _df['AMT_CREDIT'] = pd.to_numeric(_df['AMT_CREDIT_x'] + _df['AMT_CREDIT_y'])\n",
    "    _df['AMT_INCOME_TOTAL'] = pd.to_numeric(_df['AMT_INCOME_TOTAL_x'] + _df['AMT_INCOME_TOTAL_y'])\n",
    "    _df['DEF_30_CNT_SOCIAL_CIRCLE'] = pd.to_numeric(_df['DEF_30_CNT_SOCIAL_CIRCLE_x'] + _df['DEF_30_CNT_SOCIAL_CIRCLE_y'])\n",
    "    _df['FLOORSMAX_AVG'] = pd.to_numeric(_df['FLOORSMAX_AVG_x'] + _df['FLOORSMAX_AVG_y'])\n",
    "    _df['LIVINGAPARTMENTS_AVG'] = pd.to_numeric(_df['LIVINGAPARTMENTS_AVG_x'] + _df['LIVINGAPARTMENTS_AVG_y'])\n",
    "    _df['OBS_60_CNT_SOCIAL_CIRCLE'] = pd.to_numeric(_df['OBS_60_CNT_SOCIAL_CIRCLE_x'] + _df['OBS_60_CNT_SOCIAL_CIRCLE_y'])\n",
    "    _df['YEARS_BEGINEXPLUATATION_AVG'] = pd.to_numeric(_df['YEARS_BEGINEXPLUATATION_AVG_x'] + _df['YEARS_BEGINEXPLUATATION_AVG_y'])\n",
    "\n",
    "    _df = _df.drop(columns=combine)\n",
    "    # Remove exact duplicates:\n",
    "    duplicates = ['AMT_REQ_CREDIT_BUREAU_HOUR_y', \n",
    "    'CNT_FAM_MEMBERS_x', 'DAYS_EMPLOYED_y', 'NONLIVINGAPARTMENTS_AVG_y',\n",
    "    'REGION_POPULATION_RELATIVE_y', 'REG_REGION_NOT_WORK_REGION_y',\n",
    "    'WALLSMATERIAL_MODE_y', 'WEEKDAY_APPR_PROCESS_START_y']\n",
    "    \n",
    "    _df = _df.drop(columns=duplicates)\n",
    "    \n",
    "    # Low count\n",
    "    low_count = ['AMT_REQ_CREDIT_BUREAU_DAY_y', 'APARTMENTS_MODE_y', \n",
    "                 'FLOORSMAX_MEDI_y', 'NAME_TYPE_SUITE_y', 'NONLIVINGAREA_MEDI_y']\n",
    "    \n",
    "    _df = _df.drop(columns=low_count)\n",
    "    \n",
    "    # Columns with a lot of Nans\n",
    "    drop_cols=['AMT_REQ_CREDIT_BUREAU_DAY_x', 'APARTMENTS_MODE_x', 'FLOORSMAX_AVG', 'FLOORSMAX_MEDI_x',\n",
    "              'LIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_MEDI_x']\n",
    "    \n",
    "    ## Todo instead of dropping Nan maybe interpolate them?\n",
    "    _df = _df.drop(columns=drop_cols)\n",
    "    \n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dupes = prepare_x_y_merge(master_flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dupes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dupes[['OCCUPATION_TYPE', 'OCCUPATION_TYPE.1']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots = []\n",
    "pattern = re.compile(\"\\.1\")\n",
    "for col in master_dupes.columns:\n",
    "    if pattern.search(col):\n",
    "        dots.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate = REGION_RATING_CLIENT_W_CITY.1, EXT_SOURCE_1.1, DAYS_REGISTRATION.1, EXT_SOURCE_3.1,\n",
    "            LIVINGAREA_MEDI.1, HOUR_APPR_PROCESS_START, FLOORSMIN_MEDI.1, OCCUPATION_TYPE.1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_dot_1(_df):\n",
    "    dots = ['REGION_RATING_CLIENT_W_CITY.1', 'EXT_SOURCE_1.1', 'DAYS_REGISTRATION.1', 'EXT_SOURCE_3.1',\n",
    "            'LIVINGAREA_MEDI.1', 'HOUR_APPR_PROCESS_START.1', 'FLOORSMIN_MEDI.1', 'OCCUPATION_TYPE.1']\n",
    "    \n",
    "    _df = _df.drop(columns=dots)\n",
    "    \n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = drop_dot_1(master_dupes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lots_of_nas = []\n",
    "for col in md.columns:\n",
    "    if md[col].isnull().sum() > 25000:\n",
    "        lots_of_nas.append(col)\n",
    "\n",
    "print(lots_of_nas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md[lots_of_nas].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nans(_df):\n",
    "    lots_of_nans = ['IS_KAEL', 'BASEMENTAREA_AVG', 'ENTRANCES_AVG', 'FONDKAPREMONT_MODE', \n",
    "                    'OWN_CAR_AGE', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', \n",
    "                    'LIVINGAPARTMENTS_MEDI', 'WEEKDAY_APPR_PROCESS_START_x', \n",
    "                    'WALLSMATERIAL_MODE_x', 'AMT_REQ_CREDIT_BUREAU_HOUR_x', \n",
    "                    'REGION_POPULATION_RELATIVE_x', 'NONLIVINGAPARTMENTS_AVG_x', \n",
    "                    'DAYS_EMPLOYED_x', 'CNT_FAM_MEMBERS_y', 'LIVE_REGION_NOT_WORK_REGION', \n",
    "                    'REG_REGION_NOT_LIVE_REGION', 'NAME_HOUSING_TYPE', 'NAME_CONTRACT_TYPE', \n",
    "                    'LIVINGAPARTMENTS_AVG_y', 'EXT_SOURCE_1', 'LIVINGAREA_MEDI', 'FLOORSMIN_MEDI',\n",
    "                    'OCCUPATION_TYPE', 'LANDAREA_MEDI', 'LANDAREA_MEDI.1', 'YEARS_BEGINEXPLUATATION_AVG',\n",
    "                    # Empty?\n",
    "                    'DEF_30_CNT_SOCIAL_CIRCLE_y', 'OBS_60_CNT_SOCIAL_CIRCLE_y', 'REG_REGION_NOT_WORK_REGION_x',\n",
    "                   'AMT_CREDIT_y', 'AMT_INCOME_TOTAL_y']\n",
    "    \n",
    "    _df = _df.drop(columns=lots_of_nans)\n",
    "    \n",
    "    # These have not so many nans but a lot for the target variable\n",
    "    not_so_many= ['EXT_SOURCE_3','YEARS_BEGINEXPLUATATION_AVG_y','FLOORSMAX_AVG_y']\n",
    "    _df = _df.drop(columns=not_so_many)\n",
    "    \n",
    "    # We are using the average for the others\n",
    "    means = ['DEF_60_CNT_SOCIAL_CIRCLE',\n",
    "     'AMT_ANNUITY', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE']\n",
    "    \n",
    "    for col in means:\n",
    "        _df[col] = _df[col].fillna(_df[col].mean())\n",
    "        \n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = drop_nans(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['NAME_TYPE_SUITE_x', 'CODE_GENDER', 'NAME_FAMILY_STATUS', 'name_education_type', 'name_income_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_numeric = ['AMT_GOODS_PRICE', 'EXT_SOURCE_2', 'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_cats = ['ORGANIZATION_TYPE', 'ORGANIZATION_TYPE_CAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dtypes(_df):\n",
    "    interrogation  = ['FLOORSMIN_AVG', 'TOTALAREA_MODE', 'FLOORSMIN_MODE', 'NONLIVINGAREA_AVG', 'HOUSETYPE_MODE', 'LANDAREA_AVG',\n",
    "    'ELEVATORS_AVG', 'COMMONAREA_MODE']\n",
    "    \n",
    "    _df = _df.drop(columns=interrogation)\n",
    "    \n",
    "    # categoricals to dummies\n",
    "    cats = ['NAME_TYPE_SUITE_x', 'CODE_GENDER', 'NAME_FAMILY_STATUS', 'name_education_type', 'name_income_type']\n",
    "    \n",
    "    _df = pd.get_dummies(_df, columns=cats, drop_first=True)\n",
    "    \n",
    "    #convert\n",
    "    to_numeric = ['AMT_GOODS_PRICE', 'EXT_SOURCE_2', 'REGION_RATING_CLIENT']\n",
    "    \n",
    "    _df['AMT_GOODS_PRICE'] = pd.to_numeric(_df['AMT_GOODS_PRICE'].apply(lambda x: x.split('€')[0]))\n",
    "    _df['EXT_SOURCE_2'] = pd.to_numeric(_df['EXT_SOURCE_2'].apply(lambda x: x.split('%')[0]), errors='coerce')\n",
    "    _df.loc[100004,'REGION_RATING_CLIENT'] = 2\n",
    "    \n",
    "    #drop wide cats\n",
    "    wide_cats = ['ORGANIZATION_TYPE', 'ORGANIZATION_TYPE_CAT']\n",
    "    _df = _df.drop(columns=wide_cats)\n",
    "    \n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dtypes = prepare_dtypes(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dtypes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_dtypes.to_csv('../data/processed/master_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
